{\rtf1\ansi\deff0\deflang1033\plain\margl1440\margr1440\fs24\fet1{\fonttbl{\f0\froman Times New Roman;}}
{{\pard\sl360\sa240\slmult1\ql{{\fs36 Bibliography}}\par}}
{{\pard\sl360\sa0\slmult1 {[1]}{V. R. Joseph, \uc0\u8220 Optimal ratio for data splitting,\uc0\u8221  {\i Statistical Analysis and Data Mining: The ASA Data Science Journal}, vol. 15, no. 4, pp. 531\uc0\u8211 538, Apr. 2022, doi: {\field{\*\fldinst{HYPERLINK "https://doi.org/10.1002/sam.11583"}}{\fldrslt https://doi.org/10.1002/sam.11583}}.}\par}}
{{\pard\sl360\sa0\slmult1 {[2]}{S. Shahinfar, P. Meek, and G. Falzon, \uc0\u8220 How many images do I need? Understanding how sample size per class affects deep learning model performance metrics for balanced designs in autonomous wildlife monitoring,\uc0\u8221  {\i arXiv.org}, Oct. 16, 2020. {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/2010.08186"}}{\fldrslt https://arxiv.org/abs/2010.08186}} (accessed May 19, 2023).}\par}}
{{\pard\sl360\sa0\slmult1 {[3]}{\uc0\u8220 SeleniumHQ Browser Automation,\uc0\u8221  {\i www.selenium.dev}. {\field{\*\fldinst{HYPERLINK "https://www.selenium.dev/"}}{\fldrslt https://www.selenium.dev/}}}\par}}
{{\pard\sl360\sa0\slmult1 {[4]}{\uc0\u8220 Albumentations,\uc0\u8221  {\i albumentations.ai}. {\field{\*\fldinst{HYPERLINK "https://albumentations.ai/"}}{\fldrslt https://albumentations.ai/}}}\par}}
{{\pard\sl360\sa0\slmult1 {[5]}{NGSS Science and Engineering Practices, \uc0\u8220 Practices of Science: Precision vs. Accuracy | manoa.hawaii.edu/ExploringOurFluidEarth,\uc0\u8221  {\i Hawaii.edu}, 2020. {\field{\*\fldinst{HYPERLINK "https://manoa.hawaii.edu/exploringourfluidearth/physical/world-ocean/map-distortion/practices-science-precision-vs-accuracy"}}{\fldrslt https://manoa.hawaii.edu/exploringourfluidearth/physical/world-ocean/map-distortion/practices-science-precision-vs-accuracy}}}\par}}
{{\pard\sl360\sa0\slmult1 {[6]}{J. Davis and M. Goadrich, \uc0\u8220 The Relationship Between Precision-Recall and ROC Curves.\uc0\u8221  Available: {\field{\*\fldinst{HYPERLINK "https://www.biostat.wisc.edu/~page/rocpr.pdf"}}{\fldrslt https://www.biostat.wisc.edu/~page/rocpr.pdf}}}\par}}
{{\pard\sl360\sa0\slmult1 {[7]}{S. A. Hicks {\i et al.}, \uc0\u8220 On evaluation metrics for medical applications of artificial intelligence,\uc0\u8221  {\i Scientific Reports}, vol. 12, no. 1, p. 5979, Apr. 2022, doi: {\field{\*\fldinst{HYPERLINK "https://doi.org/10.1038/s41598-022-09954-8"}}{\fldrslt https://doi.org/10.1038/s41598-022-09954-8}}.}\par}}
{{\pard\sl360\sa0\slmult1 {[8]}{\uc0\u8220 Visual Geometry Group - University of Oxford,\uc0\u8221  {\i www.robots.ox.ac.uk}. {\field{\*\fldinst{HYPERLINK "https://www.robots.ox.ac.uk/~vgg/data/flowers/102/"}}{\fldrslt https://www.robots.ox.ac.uk/~vgg/data/flowers/102/}}}\par}}
{{\pard\sl360\sa0\slmult1 {[9]}{\uc0\u8220 A Recipe for Training Neural Networks,\uc0\u8221  {\i karpathy.github.io}. {\field{\*\fldinst{HYPERLINK "http://karpathy.github.io/2019/04/25/recipe/"}}{\fldrslt http://karpathy.github.io/2019/04/25/recipe/}}}\par}}
{{\pard\sl360\sa0\slmult1 {[10]}{M. Tan and Q. V. Le, \uc0\u8220 EfficientNetV2: Smaller Models and Faster Training,\uc0\u8221  {\i arXiv:2104.00298 [cs]}, Jun. 2021, Available: {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/2104.00298"}}{\fldrslt https://arxiv.org/abs/2104.00298}}}\par}}
{{\pard\sl360\sa0\slmult1 {[11]}{S. Ioffe and C. Szegedy, \uc0\u8220 Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift,\uc0\u8221  {\i arXiv.org}, 2015. {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/1502.03167"}}{\fldrslt https://arxiv.org/abs/1502.03167}}}\par}}
{{\pard\sl360\sa0\slmult1 {[12]}{N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov, \uc0\u8220 Dropout: A Simple Way to Prevent Neural Networks from Overfitting,\uc0\u8221  {\i Journal of Machine Learning Research}, vol. 15, no. 56, pp. 1929\uc0\u8211 1958, 2014, Available: {\field{\*\fldinst{HYPERLINK "https://jmlr.org/papers/v15/srivastava14a.html"}}{\fldrslt https://jmlr.org/papers/v15/srivastava14a.html}}}\par}}
{{\pard\sl360\sa0\slmult1 {[13]}{I. Loshchilov and F. Hutter, \uc0\u8220 Decoupled Weight Decay Regularization,\uc0\u8221  {\i arXiv.org}, Jan. 04, 2019. {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/1711.05101v3"}}{\fldrslt https://arxiv.org/abs/1711.05101v3}} (accessed May 19, 2023).}\par}}
{{\pard\sl360\sa0\slmult1 {[14]}{S. Ruder, \uc0\u8220 An overview of gradient descent optimization algorithms,\uc0\u8221  {\i arXiv.org}, 2016. {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/1609.04747"}}{\fldrslt https://arxiv.org/abs/1609.04747}}}\par}}
{{\pard\sl360\sa0\slmult1 {[15]}{P. Zhou, J. Feng, C. Ma, C. Xiong, S. Hoi, and W. E, \uc0\u8220 Towards Theoretically Understanding Why SGD Generalizes Better Than ADAM in Deep Learning,\uc0\u8221  {\i arXiv:2010.05627 [cs, math, stat]}, Nov. 2021, Available: {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/2010.05627"}}{\fldrslt https://arxiv.org/abs/2010.05627}}}\par}}
{{\pard\sl360\sa0\slmult1 {[16]}{D. Hendrycks and K. Gimpel, \uc0\u8220 Gaussian Error Linear Units (GELUs),\uc0\u8221  {\i arXiv:1606.08415 [cs]}, Jul. 2020, Available: {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/1606.08415"}}{\fldrslt https://arxiv.org/abs/1606.08415}}}\par}}
{{\pard\sl360\sa0\slmult1 {[17]}{Agarap, Abien Fred, \uc0\u8220 Deep Learning using Rectified Linear Units (ReLU),\uc0\u8221  {\i arXiv.org}, 2018. {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/1803.08375"}}{\fldrslt https://arxiv.org/abs/1803.08375}}}\par}}
{{\pard\sl360\sa0\slmult1 {[18]}{K. O\uc0\u8217 Shea and R. Nash, \uc0\u8220 An Introduction to Convolutional Neural Networks,\uc0\u8221  {\i arXiv:1511.08458 [cs]}, Dec. 2015, Available: {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/1511.08458"}}{\fldrslt https://arxiv.org/abs/1511.08458}}}\par}}
{{\pard\sl360\sa0\slmult1 {[19]}{S. Ray, \uc0\u8220 A Quick Review of Machine Learning Algorithms,\uc0\u8221  {\i IEEE Xplore}, Feb. 01, 2019. {\field{\*\fldinst{HYPERLINK "https://ieeexplore.ieee.org/document/8862451"}}{\fldrslt https://ieeexplore.ieee.org/document/8862451}}}\par}}
{{\pard\sl360\sa0\slmult1 {[20]}{A. Rana, A. Singh Rawat, A. Bijalwan, and H. Bahuguna, \uc0\u8220 Application of Multi Layer (Perceptron) Artificial Neural Network in the Diagnosis System: A Systematic Review,\uc0\u8221  {\i IEEE Xplore}, Aug. 01, 2018. {\field{\*\fldinst{HYPERLINK "https://ieeexplore.ieee.org/abstract/document/8509069"}}{\fldrslt https://ieeexplore.ieee.org/abstract/document/8509069}} (accessed May 13, 2023).}\par}}
{{\pard\sl360\sa0\slmult1 {[21]}{\uc0\u8220 Lesson 11: Principal Components Analysis (PCA) | STAT 505,\uc0\u8221  {\i PennState: Statistics Online Courses}. {\field{\*\fldinst{HYPERLINK "https://online.stat.psu.edu/stat505/lesson/11"}}{\fldrslt https://online.stat.psu.edu/stat505/lesson/11}}}\par}}
{{\pard\sl360\sa0\slmult1 {[22]}{\uc0\u8220 Singular Value Decomposition (SVD) tutorial,\uc0\u8221  {\i web.mit.edu}. {\field{\*\fldinst{HYPERLINK "https://web.mit.edu/be.400/www/SVD/Singular_Value_Decomposition.htm"}}{\fldrslt https://web.mit.edu/be.400/www/SVD/Singular_Value_Decomposition.htm}}}\par}}
{{\pard\sl360\sa0\slmult1 {[23]}{A. Krizhevsky, I. Sutskever, and G. E. Hinton, \uc0\u8220 ImageNet Classification with Deep Convolutional Neural Networks,\uc0\u8221  {\i Neural Information Processing Systems}, 2012. {\field{\*\fldinst{HYPERLINK "https://papers.nips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html"}}{\fldrslt https://papers.nips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html}}}\par}}
{{\pard\sl360\sa0\slmult1 {[24]}{O. Russakovsky {\i et al.}, \uc0\u8220 ImageNet Large Scale Visual Recognition Challenge,\uc0\u8221  {\i arXiv.org}, 2014. {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/1409.0575"}}{\fldrslt https://arxiv.org/abs/1409.0575}}}\par}}
{{\pard\sl360\sa0\slmult1 {[25]}{K. He, X. Zhang, S. Ren, and J. Sun, \uc0\u8220 Deep Residual Learning for Image Recognition,\uc0\u8221  {\i arXiv.org}, Dec. 10, 2015. {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/1512.03385"}}{\fldrslt https://arxiv.org/abs/1512.03385}}}\par}}
{{\pard\sl360\sa0\slmult1 {[26]}{C. Szegedy {\i et al.}, \uc0\u8220 Going Deeper with Convolutions,\uc0\u8221  {\i arXiv.org}, 2014. {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/1409.4842"}}{\fldrslt https://arxiv.org/abs/1409.4842}}}\par}}
{{\pard\sl360\sa0\slmult1 {[27]}{K. Simonyan and A. Zisserman, \uc0\u8220 Very Deep Convolutional Networks for Large-Scale Image Recognition,\uc0\u8221  {\i arXiv.org}, 2014. {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/1409.1556"}}{\fldrslt https://arxiv.org/abs/1409.1556}}}\par}}
{{\pard\sl360\sa0\slmult1 {[28]}{M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, and L.-C. Chen, \uc0\u8220 MobileNetV2: Inverted Residuals and Linear Bottlenecks,\uc0\u8221  {\i arXiv.org}, 2018. {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/1801.04381"}}{\fldrslt https://arxiv.org/abs/1801.04381}}}\par}}
{{\pard\sl360\sa0\slmult1 {[29]}{A. G. Howard {\i et al.}, \uc0\u8220 MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications,\uc0\u8221  {\i arXiv.org}, 2017. {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/1704.04861"}}{\fldrslt https://arxiv.org/abs/1704.04861}}}\par}}
{{\pard\sl360\sa0\slmult1 {[30]}{M. Tan and Q. V. Le, \uc0\u8220 EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,\uc0\u8221  {\i arXiv.org}, 2019. {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/1905.11946"}}{\fldrslt https://arxiv.org/abs/1905.11946}}}\par}}
{{\pard\sl360\sa0\slmult1 {[31]}{J. Redmon and A. Farhadi, \uc0\u8220 YOLOv3: An Incremental Improvement,\uc0\u8221  {\i arXiv.org}, 2018. {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/1804.02767"}}{\fldrslt https://arxiv.org/abs/1804.02767}}}\par}}
{{\pard\sl360\sa0\slmult1 {[32]}{J. Redmon and A. Farhadi, \uc0\u8220 YOLO9000: Better, Faster, Stronger,\uc0\u8221  {\i arXiv.org}, 2016. {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/1612.08242"}}{\fldrslt https://arxiv.org/abs/1612.08242}}}\par}}
{{\pard\sl360\sa0\slmult1 {[33]}{A. Bochkovskiy, C.-Y. Wang, and H.-Y. M. Liao, \uc0\u8220 YOLOv4: Optimal Speed and Accuracy of Object Detection,\uc0\u8221  Apr. 2020, Available: {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/2004.10934"}}{\fldrslt https://arxiv.org/abs/2004.10934}}}\par}}
{{\pard\sl360\sa0\slmult1 {[34]}{C.-Y. Wang, H.-Y. M. Liao, I.-H. Yeh, Y.-H. Wu, P.-Y. Chen, and J.-W. Hsieh, \uc0\u8220 CSPNet: A New Backbone that can Enhance Learning Capability of CNN,\uc0\u8221  {\i arXiv:1911.11929 [cs]}, Nov. 2019, Available: {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/1911.11929"}}{\fldrslt https://arxiv.org/abs/1911.11929}}}\par}}
{{\pard\sl360\sa0\slmult1 {[35]}{K. Weiss, T. M. Khoshgoftaar, and D. Wang, \uc0\u8220 A survey of transfer learning,\uc0\u8221  {\i Journal of Big Data}, vol. 3, no. 1, May 2016, doi: {\field{\*\fldinst{HYPERLINK "https://doi.org/10.1186/s40537-016-0043-6"}}{\fldrslt https://doi.org/10.1186/s40537-016-0043-6}}.}\par}}
{{\pard\sl360\sa0\slmult1 {[36]}{J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, \uc0\u8220 ImageNet: A large-scale hierarchical image database,\uc0\u8221  {\i 2009 IEEE Conference on Computer Vision and Pattern Recognition}, Jun. 2009, doi: {\field{\*\fldinst{HYPERLINK "https://doi.org/10.1109/cvpr.2009.5206848"}}{\fldrslt https://doi.org/10.1109/cvpr.2009.5206848}}.}\par}}
{{\pard\sl360\sa0\slmult1 {[37]}{A. Hassani, S. Walton, N. Shah, A. Abuduweili, J. Li, and H. Shi, \uc0\u8220 Escaping the Big Data Paradigm with Compact Transformers,\uc0\u8221  {\i arXiv:2104.05704 [cs]}, Aug. 2021, Available: {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/2104.05704"}}{\fldrslt https://arxiv.org/abs/2104.05704}}}\par}}
{{\pard\sl360\sa0\slmult1 {[38]}{A. Dosovitskiy {\i et al.}, \uc0\u8220 An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale,\uc0\u8221  {\i arXiv:2010.11929 [cs]}, Oct. 2020, Available: {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/2010.11929"}}{\fldrslt https://arxiv.org/abs/2010.11929}}}\par}}
{{\pard\sl360\sa0\slmult1 {[39]}{X. Chen, C.-J. Hsieh, and B. Gong, \uc0\u8220 When Vision Transformers Outperform ResNets without Pre-training or Strong Data Augmentations,\uc0\u8221  {\i arXiv.org}, Mar. 13, 2022. {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/2106.01548"}}{\fldrslt https://arxiv.org/abs/2106.01548}} (accessed May 19, 2023).}\par}}
{{\pard\sl360\sa0\slmult1 {[40]}{R. Wightman, H. Touvron, and H. J\uc0\u233 gou, \uc0\u8220 ResNet strikes back: An improved training procedure in timm,\uc0\u8221  {\i arXiv.org}, Oct. 01, 2021. {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/2110.00476"}}{\fldrslt https://arxiv.org/abs/2110.00476}} (accessed May 19, 2023).}\par}}
{{\pard\sl360\sa0\slmult1 {[41]}{Google, \uc0\u8220 Google Colaboratory,\uc0\u8221  {\i Google.com}, 2019. {\field{\*\fldinst{HYPERLINK "https://colab.research.google.com/"}}{\fldrslt https://colab.research.google.com/}}}\par}}
{{\pard\sl360\sa0\slmult1 {[42]}{H. M\uc0\u252 ller, W. M\uc0\u252 ller, D. McG. Squire, S. Marchand-Maillet, and T. Pun, \uc0\u8220 Performance evaluation in content-based image retrieval: overview and proposals,\uc0\u8221  {\i Pattern Recognition Letters}, vol. 22, no. 5, pp. 593\uc0\u8211 601, Apr. 2001, doi: {\field{\*\fldinst{HYPERLINK "https://doi.org/10.1016/s0167-8655(00)00118-5"}}{\fldrslt https://doi.org/10.1016/s0167-8655(00)00118-5}}.}\par}}
{{\pard\sl360\sa0\slmult1 {[43]}{\uc0\u8220 Section 8 (Week 8),\uc0\u8221  {\i cs230.stanford.edu}. {\field{\*\fldinst{HYPERLINK "https://cs230.stanford.edu/section/8/"}}{\fldrslt https://cs230.stanford.edu/section/8/}}}\par}}
{{\pard\sl360\sa0\slmult1 {[44]}{\uc0\u8220 Evaluation in information retrieval,\uc0\u8221  {\i nlp.stanford.edu}. {\field{\*\fldinst{HYPERLINK "https://nlp.stanford.edu/IR-book/html/htmledition/evaluation-in-information-retrieval-1.html"}}{\fldrslt https://nlp.stanford.edu/IR-book/html/htmledition/evaluation-in-information-retrieval-1.html}}}\par}}
{{\pard\sl360\sa0\slmult1 {[45]}{X. Li, J. Yang, and J. Ma, \uc0\u8220 Recent developments of content-based image retrieval (CBIR),\uc0\u8221  {\i Neurocomputing}, vol. 452, pp. 675\uc0\u8211 689, Sep. 2021, doi: {\field{\*\fldinst{HYPERLINK "https://doi.org/10.1016/j.neucom.2020.07.139"}}{\fldrslt https://doi.org/10.1016/j.neucom.2020.07.139}}.}\par}}
{{\pard\sl360\sa0\slmult1 {[46]}{O. Kramer, \uc0\u8220 K-Nearest Neighbors,\uc0\u8221  {\i Dimensionality Reduction with Unsupervised Nearest Neighbors}, vol. 51, pp. 13\uc0\u8211 23, 2013, doi: {\field{\*\fldinst{HYPERLINK "https://doi.org/10.1007/978-3-642-38652-7_2"}}{\fldrslt https://doi.org/10.1007/978-3-642-38652-7_2}}.}\par}}
{{\pard\sl360\sa0\slmult1 {[47]}{G. E. Hinton, \uc0\u8220 Reducing the Dimensionality of Data with Neural Networks,\uc0\u8221  {\i Science}, vol. 313, no. 5786, pp. 504\uc0\u8211 507, Jul. 2006, doi: {\field{\*\fldinst{HYPERLINK "https://doi.org/10.1126/science.1127647"}}{\fldrslt https://doi.org/10.1126/science.1127647}}.}\par}}
{{\pard\sl360\sa0\slmult1 {[48]}{A. Krizhevsky and G. E. Hinton, \uc0\u8220 Using very deep autoencoders for content-based image retrieval,\uc0\u8221  {\i Semantic Scholar}, 2011. {\field{\*\fldinst{HYPERLINK "https://www.semanticscholar.org/paper/Using-very-deep-autoencoders-for-content-based-Krizhevsky-Hinton/88080d28536f36588740737f3b7a1f6c1a409654"}}{\fldrslt https://www.semanticscholar.org/paper/Using-very-deep-autoencoders-for-content-based-Krizhevsky-Hinton/88080d28536f36588740737f3b7a1f6c1a409654}} (accessed May 19, 2023).}\par}}
{{\pard\sl360\sa0\slmult1 {[49]}{E. Hoffer and N. Ailon, \uc0\u8220 Deep metric learning using Triplet network,\uc0\u8221  {\i arXiv:1412.6622 [cs, stat]}, Dec. 2018, Available: {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/1412.6622"}}{\fldrslt https://arxiv.org/abs/1412.6622}}}\par}}
{{\pard\sl360\sa0\slmult1 {[50]}{J. Daniel and J. Martin, \uc0\u8220 Speech and Language Processing.\uc0\u8221  Available: {\field{\*\fldinst{HYPERLINK "https://web.stanford.edu/~jurafsky/slp3/5.pdf"}}{\fldrslt https://web.stanford.edu/~jurafsky/slp3/5.pdf}}}\par}}
{{\pard\sl360\sa0\slmult1 {[51]}{\uc0\u8220 scipy.spatial.distance.correlation \uc0\u8212  SciPy v1.10.1 Manual,\uc0\u8221  {\i docs.scipy.org}. {\field{\*\fldinst{HYPERLINK "https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.correlation.html"}}{\fldrslt https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.correlation.html}} (accessed May 19, 2023).}\par}}
{{\pard\sl360\sa0\slmult1 {[52]}{S. Bai, P. Tang, P. H. S. Torr, and L. J. Latecki, \uc0\u8220 Re-Ranking via Metric Fusion for Object Retrieval and Person Re-Identification,\uc0\u8221  {\i IEEE Xplore}, Jun. 01, 2019. {\field{\*\fldinst{HYPERLINK "https://ieeexplore.ieee.org/document/8953719"}}{\fldrslt https://ieeexplore.ieee.org/document/8953719}} (accessed May 19, 2023).}\par}}
{{\pard\sl360\sa0\slmult1 {[53]}{L. Zheng, L. Shen, L. Tian, S. Wang, J. Wang, and Q. Tian, \uc0\u8220 Scalable Person Re-identification: A Benchmark,\uc0\u8221  {\i IEEE Xplore}, Dec. 01, 2015. {\field{\*\fldinst{HYPERLINK "https://ieeexplore.ieee.org/document/7410490"}}{\fldrslt https://ieeexplore.ieee.org/document/7410490}}}\par}}
{{\pard\sl360\sa0\slmult1 {[54]}{R. Cao {\i et al.}, \uc0\u8220 Enhancing remote sensing image retrieval using a triplet deep metric learning network,\uc0\u8221  {\i International Journal of Remote Sensing}, vol. 41, no. 2, pp. 740\uc0\u8211 751, Aug. 2019, doi: {\field{\*\fldinst{HYPERLINK "https://doi.org/10.1080/2150704x.2019.1647368"}}{\fldrslt https://doi.org/10.1080/2150704x.2019.1647368}}.}\par}}
{{\pard\sl360\sa0\slmult1 {[55]}{S. Ren, K. He, R. Girshick, and J. Sun, \uc0\u8220 Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks,\uc0\u8221  {\i arXiv.org}, 2015. {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/1506.01497"}}{\fldrslt https://arxiv.org/abs/1506.01497}}}\par}}
{{\pard\sl360\sa0\slmult1 {[56]}{K. He, G. Gkioxari, P. Doll\uc0\u225 r, and R. Girshick, \uc0\u8220 Mask R-CNN,\uc0\u8221  {\i arXiv.org}, 2017. {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/1703.06870"}}{\fldrslt https://arxiv.org/abs/1703.06870}}}\par}}
{{\pard\sl360\sa0\slmult1 {[57]}{C. Wang {\i et al.}, \uc0\u8220 Natural compounds with xanthine oxidase inhibitory activity: A review,\uc0\u8221  vol. 93, no. 4, pp. 387\uc0\u8211 418, Jan. 2019, doi: {\field{\*\fldinst{HYPERLINK "https://doi.org/10.1111/cbdd.13437"}}{\fldrslt https://doi.org/10.1111/cbdd.13437}}.}\par}}
{{\pard\sl360\sa0\slmult1 {[58]}{\uc0\u8220 Chrysanthemum hybridization in 21st century \uc0\u8211  A review,\uc0\u8221  {\i Journal of Ornamental Horticulture}, vol. 23, no. 2, 2020, Accessed: May 19, 2023. [Online]. Available: {\field{\*\fldinst{HYPERLINK "https://www.indianjournals.com/ijor.aspx?target=ijor:joh&volume=23&issue=2&article=001"}}{\fldrslt https://www.indianjournals.com/ijor.aspx?target=ijor:joh&volume=23&issue=2&article=001}}}\par}}
{{\pard\sl360\sa0\slmult1 {[59]}{G. Mathys and E. A. Baker, \uc0\u8220 An Appraisal of the Effectiveness of Quarantines,\uc0\u8221  {\i Annual Review of Phytopathology}, vol. 18, no. 1, pp. 85\uc0\u8211 101, Sep. 1980, doi: {\field{\*\fldinst{HYPERLINK "https://doi.org/10.1146/annurev.py.18.090180.000505"}}{\fldrslt https://doi.org/10.1146/annurev.py.18.090180.000505}}.}\par}}
{{\pard\sl360\sa0\slmult1 {[60]}{G. R. Rout and P. Das, \uc0\u8220 Recent trends in the biotechnology of Chrysanthemum: a critical review,\uc0\u8221  {\i Scientia Horticulturae}, vol. 69, no. 3\uc0\u8211 4, pp. 239\uc0\u8211 257, May 1997, doi: {\field{\*\fldinst{HYPERLINK "https://doi.org/10.1016/s0304-4238(97)00008-3"}}{\fldrslt https://doi.org/10.1016/s0304-4238(97)00008-3}}.}\par}}
{{\pard\sl360\sa0\slmult1 {[61]}{I. J. Goodfellow {\i et al.}, \uc0\u8220 Generative Adversarial Networks,\uc0\u8221  {\i arXiv.org}, 2014. {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/1406.2661"}}{\fldrslt https://arxiv.org/abs/1406.2661}}}\par}}
{{\pard\sl360\sa0\slmult1 {[62]}{J.-Y. Zhu, T. Park, P. Isola, and A. A. Efros, \uc0\u8220 Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks,\uc0\u8221  {\i 2017 IEEE International Conference on Computer Vision (ICCV)}, Oct. 2017, doi: {\field{\*\fldinst{HYPERLINK "https://doi.org/10.1109/iccv.2017.244"}}{\fldrslt https://doi.org/10.1109/iccv.2017.244}}.}\par}}
{{\pard\sl360\sa0\slmult1 {[63]}{P. Isola, J.-Y. Zhu, T. Zhou, and A. A. Efros, \uc0\u8220 Image-to-Image Translation with Conditional Adversarial Networks,\uc0\u8221  {\i 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, Jul. 2017, doi: {\field{\*\fldinst{HYPERLINK "https://doi.org/10.1109/cvpr.2017.632"}}{\fldrslt https://doi.org/10.1109/cvpr.2017.632}}.}\par}}
{{\pard\sl360\sa0\slmult1 {[64]}{A. Radford, L. Metz, and S. Chintala, \uc0\u8220 Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks,\uc0\u8221  {\i arXiv.org}, 2015. {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/1511.06434"}}{\fldrslt https://arxiv.org/abs/1511.06434}}}\par}}
{{\pard\sl360\sa0\slmult1 {[65]}{Y. Lu, D. Chen, E. Olaniyi, and Y. Huang, \uc0\u8220 Generative adversarial networks (GANs) for image augmentation in agriculture: A systematic review,\uc0\u8221  {\i Computers and Electronics in Agriculture}, vol. 200, p. 107208, Sep. 2022, doi: {\field{\*\fldinst{HYPERLINK "https://doi.org/10.1016/j.compag.2022.107208"}}{\fldrslt https://doi.org/10.1016/j.compag.2022.107208}}.}\par}}
{{\pard\sl360\sa0\slmult1 {[66]}{S. Mittal and S. Vaishay, \uc0\u8220 A survey of techniques for optimizing deep learning on GPUs,\uc0\u8221  {\i Journal of Systems Architecture}, vol. 99, p. 101635, Oct. 2019, doi: {\field{\*\fldinst{HYPERLINK "https://doi.org/10.1016/j.sysarc.2019.101635"}}{\fldrslt https://doi.org/10.1016/j.sysarc.2019.101635}}.}\par}}
}
